{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201: ROI exists: False, EEG exists: False\n",
      "257: ROI exists: False, EEG exists: False\n",
      "258: ROI exists: False, EEG exists: True\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "roi_folder = \"G:\\\\共用雲端硬碟\\\\CNElab_陳昱祺\\\\source localization\\\\test_data\\\\ROI\\\\Desikan_Kilianny_with_3pca\"\n",
    "eeg_folder = \"G:\\\\共用雲端硬碟\\\\CNElab_黎承宣&賴璁毅_EEG_ROI\\\\A.Dataset\\\\setfile\"\n",
    "index_data = {}\n",
    "# Modify train_dataset and test_eval as per the new requirement\n",
    "index_data[\"train_dataset\"] = [str(i) for i in range(1, 301)]\n",
    "index_data[\"test_eval\"] = [str(i) for i in range(301, 401)]\n",
    "\n",
    "# Write the updated data to a JSON file\n",
    "with open(\"subject_groups.json\", \"w\") as json_file:\n",
    "    json.dump(index_data, json_file, indent=4)\n",
    "file_status = {}\n",
    "for subject in index_data[\"train_dataset\"]:\n",
    "    roi_path = os.path.join(roi_folder, f\"processed_{subject}_ICA_DLtrain.set\")\n",
    "    eeg_path = os.path.join(eeg_folder, f\"{subject}_ICA_DLtrain.set\")\n",
    "\n",
    "    roi_exists = os.path.exists(roi_path)\n",
    "    eeg_exists = os.path.exists(eeg_path)\n",
    "\n",
    "    file_status[subject] = {\n",
    "        \"roi_exists\": roi_exists,\n",
    "        \"eeg_exists\": eeg_exists\n",
    "    }\n",
    "\n",
    "    if roi_exists == False or eeg_exists == False:\n",
    "        print(f\"{subject}: ROI exists: {roi_exists}, EEG exists: {eeg_exists}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymatreader\n",
      "  Downloading pymatreader-1.0.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: h5py in c:\\users\\user\\anaconda3\\envs\\huggingface\\lib\\site-packages (from pymatreader) (3.12.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\envs\\huggingface\\lib\\site-packages (from pymatreader) (2.0.1)\n",
      "Requirement already satisfied: scipy>=1.7.1 in c:\\users\\user\\anaconda3\\envs\\huggingface\\lib\\site-packages (from pymatreader) (1.14.1)\n",
      "Collecting xmltodict (from pymatreader)\n",
      "  Downloading xmltodict-0.14.2-py2.py3-none-any.whl.metadata (8.0 kB)\n",
      "Downloading pymatreader-1.0.0-py3-none-any.whl (9.3 kB)\n",
      "Downloading xmltodict-0.14.2-py2.py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: xmltodict, pymatreader\n",
      "Successfully installed pymatreader-1.0.0 xmltodict-0.14.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pymatreader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '180', '181', '182', '183', '184', '185', '186', '187', '188', '189', '190', '191', '192', '193', '194', '195', '196', '197', '198', '199', '200', '201', '202', '203', '204', '205', '206', '207', '208', '209', '210', '211', '212', '213', '214', '215', '216', '217', '218', '219', '220', '221', '222', '223', '224', '225', '226', '227', '228', '229', '230', '231', '232', '233', '234', '235', '236', '237', '238', '239', '240', '241', '242', '243', '244', '245', '246', '247', '248', '249', '250', '251', '252', '253', '254', '255', '256', '257', '258', '259', '260', '261', '262', '263', '264', '265', '266', '267', '268', '269', '270', '271', '272', '273', '274', '275', '276', '277', '278', '279', '280', '281', '282', '283', '284', '285', '286', '287', '288', '289', '290', '291', '292', '293', '294', '295', '296', '297', '298', '299', '300']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\huggingface\\Lib\\site-packages\\pymatreader\\utils.py:168: UserWarning: Complex objects (like classes) are not supported. They are imported on a best effort base but your mileage will vary.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading G:\\共用雲端硬碟\\CNElab_陳昱祺\\source localization\\test_data\\ROI\\Desikan_Kilianny_with_3pca\\processed_1_ICA_DLtrain.fdt\n",
      "Reading 0 ... 78878  =      0.000 ...   308.117 secs...\n",
      "Total Nan of the subject: 0\n",
      "Total Random of the subject: 97\n",
      "Reading G:\\共用雲端硬碟\\CNElab_陳昱祺\\source localization\\test_data\\ROI\\Desikan_Kilianny_with_3pca\\processed_2_ICA_DLtrain.fdt\n",
      "Reading 0 ... 77004  =      0.000 ...   300.797 secs...\n",
      "Total Nan of the subject: 0\n",
      "Total Random of the subject: 95\n",
      "Reading G:\\共用雲端硬碟\\CNElab_陳昱祺\\source localization\\test_data\\ROI\\Desikan_Kilianny_with_3pca\\processed_3_ICA_DLtrain.fdt\n",
      "Reading 0 ... 66080  =      0.000 ...   258.125 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\共用雲端硬碟\\CNElab_陳昱祺\\multi-modal\\DataLoader\\SLT_dataloader.py:192: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  eeg_data = mne.io.read_raw_eeglab(eeg_path, preload=True).get_data()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Nan of the subject: 0\n",
      "Total Random of the subject: 83\n",
      "Reading G:\\共用雲端硬碟\\CNElab_陳昱祺\\source localization\\test_data\\ROI\\Desikan_Kilianny_with_3pca\\processed_4_ICA_DLtrain.fdt\n",
      "Reading 0 ... 78059  =      0.000 ...   304.918 secs...\n",
      "Total Nan of the subject: 0\n",
      "Total Random of the subject: 102\n",
      "Reading G:\\共用雲端硬碟\\CNElab_陳昱祺\\source localization\\test_data\\ROI\\Desikan_Kilianny_with_3pca\\processed_5_ICA_DLtrain.fdt\n",
      "Reading 0 ... 77393  =      0.000 ...   302.316 secs...\n",
      "Total Nan of the subject: 0\n",
      "Total Random of the subject: 104\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, './Dataloader')\n",
    "from SLT_dataloader import EEGROIDataset, SignalDataCollator\n",
    "\n",
    "# Usage example\n",
    "roi_folder = \"G:\\\\共用雲端硬碟\\\\CNElab_陳昱祺\\\\source localization\\\\test_data\\\\ROI\\\\Desikan_Kilianny_with_3pca\"\n",
    "eeg_folder = \"G:\\\\共用雲端硬碟\\\\CNElab_陳昱祺\\\\source localization\\\\test_data\\\\ROI\\\\Desikan_Kilianny_with_3pca\"\n",
    "group_file = \"subject_groups.json\"\n",
    "\n",
    "# Create dataset\n",
    "train_dataset = EEGROIDataset(roi_folder, eeg_folder, group_file, \"train_dataset\")\n",
    "print(f\"Total dataset size: {len(train_dataset)}\")\n",
    "# Create dataset\n",
    "test_dataset = EEGROIDataset(roi_folder, eeg_folder, group_file, \"test_dataset\")\n",
    "print(f\"Total dataset size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import mne \n",
    "\n",
    "file_roi = \"G:\\\\共用雲端硬碟\\\\CNElab_黎承宣&賴璁毅_EEG_ROI\\\\A.Dataset\\\\processed_setfile\\\\processed_0_ICA_DLtrain.set\"\n",
    "file_eeg = \"G:\\\\共用雲端硬碟\\\\CNElab_黎承宣&賴璁毅_EEG_ROI\\\\A.Dataset\\\\setfile\\\\0_ICA_DLtrain.set\"\n",
    "\n",
    "with h5py.File(file_roi, 'r') as f:\n",
    "    if 'roi' in f:\n",
    "        ROI = f['roi']['source_voxel_data'][:]\n",
    "        print(ROI.shape)\n",
    "\n",
    "EEG = mne.io.read_raw_eeglab(file_eeg, preload=True)\n",
    "print(EEG.info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['156', '314', '448', '282', '513', '194', '188', '417', '133', '492', '170', '387', '300', '11', '515', '161', '337', '377', '184', '333', '489', '402', '118', '137', '395', '79', '446']\n",
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\156_ICA_DLtrain.fdt\n",
      "Reading 0 ... 58890  =      0.000 ...   230.039 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1100\\1922458980.py:54: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  eeg_data = mne.io.read_raw_eeglab(eeg_path, preload=True).get_data()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\314_ICA_DLtrain.fdt\n",
      "Reading 0 ... 77475  =      0.000 ...   302.637 secs...\n",
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\448_ICA_DLtrain.fdt\n",
      "Reading 0 ... 77731  =      0.000 ...   303.637 secs...\n",
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\282_ICA_DLtrain.fdt\n",
      "Reading 0 ... 68762  =      0.000 ...   268.602 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1100\\1922458980.py:54: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  eeg_data = mne.io.read_raw_eeglab(eeg_path, preload=True).get_data()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\513_ICA_DLtrain.fdt\n",
      "Reading 0 ... 71936  =      0.000 ...   281.000 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1100\\1922458980.py:54: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  eeg_data = mne.io.read_raw_eeglab(eeg_path, preload=True).get_data()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\194_ICA_DLtrain.fdt\n",
      "Reading 0 ... 77260  =      0.000 ...   301.797 secs...\n",
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\188_ICA_DLtrain.fdt\n",
      "Reading 0 ... 76748  =      0.000 ...   299.797 secs...\n",
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\417_ICA_DLtrain.fdt\n",
      "Reading 0 ... 76902  =      0.000 ...   300.398 secs...\n",
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\133_ICA_DLtrain.fdt\n",
      "Reading 0 ... 70964  =      0.000 ...   277.203 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1100\\1922458980.py:54: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  eeg_data = mne.io.read_raw_eeglab(eeg_path, preload=True).get_data()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\492_ICA_DLtrain.fdt\n",
      "Reading 0 ... 59229  =      0.000 ...   231.363 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1100\\1922458980.py:54: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  eeg_data = mne.io.read_raw_eeglab(eeg_path, preload=True).get_data()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\170_ICA_DLtrain.fdt\n",
      "Reading 0 ... 77158  =      0.000 ...   301.398 secs...\n",
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\387_ICA_DLtrain.fdt\n",
      "Reading 0 ... 77158  =      0.000 ...   301.398 secs...\n",
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\300_ICA_DLtrain.fdt\n",
      "Reading 0 ... 60611  =      0.000 ...   236.762 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1100\\1922458980.py:54: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  eeg_data = mne.io.read_raw_eeglab(eeg_path, preload=True).get_data()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\11_ICA_DLtrain.fdt\n",
      "Reading 0 ... 77199  =      0.000 ...   301.559 secs...\n",
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\515_ICA_DLtrain.fdt\n",
      "Reading 0 ... 59782  =      0.000 ...   233.523 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1100\\1922458980.py:54: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  eeg_data = mne.io.read_raw_eeglab(eeg_path, preload=True).get_data()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\161_ICA_DLtrain.fdt\n",
      "Reading 0 ... 80609  =      0.000 ...   314.879 secs...\n",
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\337_ICA_DLtrain.fdt\n",
      "Reading 0 ... 79667  =      0.000 ...   311.199 secs...\n",
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\377_ICA_DLtrain.fdt\n",
      "Reading 0 ... 76933  =      0.000 ...   300.520 secs...\n",
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\184_ICA_DLtrain.fdt\n",
      "Reading 0 ... 80302  =      0.000 ...   313.680 secs...\n",
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\333_ICA_DLtrain.fdt\n",
      "Reading 0 ... 62311  =      0.000 ...   243.402 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1100\\1922458980.py:54: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  eeg_data = mne.io.read_raw_eeglab(eeg_path, preload=True).get_data()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\489_ICA_DLtrain.fdt\n",
      "Reading 0 ... 87111  =      0.000 ...   340.277 secs...\n",
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\402_ICA_DLtrain.fdt\n",
      "Reading 0 ... 65301  =      0.000 ...   255.082 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1100\\1922458980.py:54: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  eeg_data = mne.io.read_raw_eeglab(eeg_path, preload=True).get_data()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\118_ICA_DLtrain.fdt\n",
      "Reading 0 ... 78551  =      0.000 ...   306.840 secs...\n",
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\137_ICA_DLtrain.fdt\n",
      "Reading 0 ... 81233  =      0.000 ...   317.316 secs...\n",
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\395_ICA_DLtrain.fdt\n",
      "Reading 0 ... 87819  =      0.000 ...   343.043 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1100\\1922458980.py:54: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  eeg_data = mne.io.read_raw_eeglab(eeg_path, preload=True).get_data()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\79_ICA_DLtrain.fdt\n",
      "Reading 0 ... 83445  =      0.000 ...   325.957 secs...\n",
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\446_ICA_DLtrain.fdt\n",
      "Reading 0 ... 61604  =      0.000 ...   240.641 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1100\\1922458980.py:54: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  eeg_data = mne.io.read_raw_eeglab(eeg_path, preload=True).get_data()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset size: 1922\n",
      "['49', '422', '90', '345', '364', '23']\n",
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\49_ICA_DLtrain.fdt\n",
      "Reading 0 ... 59760  =      0.000 ...   233.438 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1100\\1922458980.py:54: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  eeg_data = mne.io.read_raw_eeglab(eeg_path, preload=True).get_data()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\422_ICA_DLtrain.fdt\n",
      "Reading 0 ... 76799  =      0.000 ...   299.996 secs...\n",
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\90_ICA_DLtrain.fdt\n",
      "Reading 0 ... 59464  =      0.000 ...   232.281 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1100\\1922458980.py:54: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  eeg_data = mne.io.read_raw_eeglab(eeg_path, preload=True).get_data()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\345_ICA_DLtrain.fdt\n",
      "Reading 0 ... 80220  =      0.000 ...   313.359 secs...\n",
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\364_ICA_DLtrain.fdt\n",
      "Reading 0 ... 77168  =      0.000 ...   301.438 secs...\n",
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\23_ICA_DLtrain.fdt\n",
      "Reading 0 ... 60407  =      0.000 ...   235.965 secs...\n",
      "Total dataset size: 399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1100\\1922458980.py:54: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  eeg_data = mne.io.read_raw_eeglab(eeg_path, preload=True).get_data()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "import mne\n",
    "import json\n",
    "import time\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class EEGROIDataset(Dataset):\n",
    "    def __init__(self, roi_folder, eeg_folder, group_file , group_index, overlap=0.5, window_size=500):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            roi_folder (str): Path to the folder containing ROI .set files.\n",
    "            eeg_folder (str): Path to the folder containing EEG .set files.\n",
    "            overlap (float): Fraction of overlap between consecutive windows (0 <= overlap < 1).\n",
    "            window_size (int): Number of samples in each window.\n",
    "        \"\"\"\n",
    "        self.roi_folder = roi_folder\n",
    "        self.eeg_folder = eeg_folder\n",
    "        self.group_file = group_file\n",
    "        self.group_index = group_index\n",
    "        self.overlap = overlap\n",
    "        self.window_size = window_size\n",
    "        self.subjects = self._get_subject_list()\n",
    "\n",
    "        self.eeg_data = []  # Will store tuples of (ROI segment, EEG segment)\n",
    "        self.roi_data = []\n",
    "        self._prepare_dataset()\n",
    "\n",
    "    def _get_subject_list(self):\n",
    "        \"\"\"Gets the list of subjects based on file names in the ROI folder.\"\"\"\n",
    "        with open(self.group_file, 'r') as f:\n",
    "            groups = json.load(f)\n",
    "\n",
    "        subject_indices = groups.get(str(self.group_index), [])\n",
    "        print(subject_indices)\n",
    "        return subject_indices \n",
    "\n",
    "    def _prepare_dataset(self):\n",
    "        \"\"\"Reads and processes data for all subjects.\"\"\"\n",
    "        for subject in self.subjects:\n",
    "            # start_time = time.time()\n",
    "            roi_path = os.path.join(self.roi_folder, f\"processed_{subject}_ICA_DLtrain.set\")\n",
    "            eeg_path = os.path.join(self.eeg_folder, f\"{subject}_ICA_DLtrain.set\")\n",
    "\n",
    "            # Load ROI data\n",
    "            with h5py.File(roi_path, 'r') as f:\n",
    "                if 'roi' in f:\n",
    "                    roi_data = f['roi']['source_voxel_data'][:]\n",
    "                    # print(roi_data.shape)\n",
    "\n",
    "            # Load EEG data\n",
    "            eeg_data = mne.io.read_raw_eeglab(eeg_path, preload=True).get_data()\n",
    "            # end_time = time.time()\n",
    "            # print(f\"Load Data time: {end_time - start_time}\")\n",
    "            # Verify dimensions\n",
    "            assert roi_data.shape[0] == 3, f\"Unexpected ROI shape: {roi_data.shape}\"\n",
    "            assert roi_data.shape[1] == 5003, f\"Unexpected ROI shape: {roi_data.shape}\"\n",
    "            assert eeg_data.shape[0] == 30, f\"Unexpected EEG shape: {eeg_data.shape}\"\n",
    "\n",
    "            # Process and overlap data\n",
    "            # start_time = time.time()\n",
    "            self._process_subject_data(roi_data, eeg_data)\n",
    "            # end_time = time.time()\n",
    "            # print(f\"Overlapping time: {end_time - start_time}\")\n",
    "            \n",
    "    def _process_subject_data(self, roi_data, eeg_data):\n",
    "        \"\"\"Segments and overlaps data for a single subject.\"\"\"\n",
    "        time_len = int(int(eeg_data.shape[1] / 256) / 2)*2\n",
    "        # print(time_len)\n",
    "        eeg_window_size = 256 * 2\n",
    "        roi_window_size = 200 * 2\n",
    "        for start_idx in range(0, time_len, 2):\n",
    "            eeg_step = start_idx * 256\n",
    "            eeg_segment = eeg_data[:, eeg_step:eeg_step+eeg_window_size]\n",
    "\n",
    "            roi_step = start_idx * 200\n",
    "            roi_segment = roi_data[:, :, roi_step:roi_step+roi_window_size]\n",
    "            \n",
    "            if roi_segment.shape[2] == roi_window_size:\n",
    "                roi_segment_reshape = roi_segment.reshape(-1, roi_window_size) \n",
    "                # print(roi_segment_reshape.shape)\n",
    "                self.roi_data.append(roi_segment_reshape)\n",
    "                self.eeg_data.append(eeg_segment)\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.eeg_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"src\": self.eeg_data[idx], \n",
    "            \"tgt\": self.eeg_data[idx], \n",
    "            \"src_mask\": None,\n",
    "            \"tgt_mask\": None,\n",
    "            \"label\": self.roi_data[idx]\n",
    "        }\n",
    "\n",
    "# Usage example\n",
    "roi_folder = \"G:\\\\共用雲端硬碟\\\\CNElab_黎承宣&賴璁毅_EEG_ROI\\\\A.Dataset\\\\processed_setfile\"\n",
    "eeg_folder = \"G:\\\\共用雲端硬碟\\\\CNElab_黎承宣&賴璁毅_EEG_ROI\\\\A.Dataset\\\\setfile\"\n",
    "group_file = \"subject_groups.json\"\n",
    "group_index = 0\n",
    "\n",
    "# Create dataset\n",
    "train_dataset = EEGROIDataset(roi_folder, eeg_folder, group_file, group_index)\n",
    "print(f\"Total dataset size: {len(train_dataset)}\")\n",
    "# Create dataset\n",
    "test_dataset = EEGROIDataset(roi_folder, eeg_folder, group_file, \"train\")\n",
    "print(f\"Total dataset size: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "import mne\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "roi_folder = \"G:\\\\共用雲端硬碟\\\\CNElab_黎承宣&賴璁毅_EEG_ROI\\\\A.Dataset\\\\processed_setfile\"\n",
    "eeg_folder = \"G:\\\\共用雲端硬碟\\\\CNElab_黎承宣&賴璁毅_EEG_ROI\\\\A.Dataset\\\\setfile\"\n",
    "roi_folder_ls = [f.split('_')[1] for f in os.listdir(roi_folder) if f.endswith('.set')]\n",
    "\n",
    "shape_list = []\n",
    "\n",
    "for subject in roi_folder_ls:\n",
    "    roi_path = os.path.join(roi_folder, f\"processed_{subject}_ICA_DLtrain.set\")\n",
    "    eeg_path = os.path.join(eeg_folder, f\"{subject}_ICA_DLtrain.set\")\n",
    "    # Load ROI data\n",
    "    with h5py.File(roi_path, 'r') as f:\n",
    "        if 'roi' in f:\n",
    "            roi_data = f['roi']['source_voxel_data'][:]\n",
    "            print(roi_data.shape)\n",
    "\n",
    "    # Load EEG data\n",
    "    eeg_data = mne.io.read_raw_eeglab(eeg_path, preload=True).get_data()\n",
    "    print(eeg_data.shape)\n",
    "    shape_list.append((roi_data.shape, eeg_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save File Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "\n",
    "def save_filenames_to_file(folder_path, output_file):\n",
    "    \"\"\"\n",
    "    Reads all filenames in a folder and saves them to a specified file.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): Path to the folder containing files.\n",
    "        output_file (str): Path to the output file to save filenames.\n",
    "    \"\"\"\n",
    "    # Get all filenames in the folder\n",
    "    filenames = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "\n",
    "    # Save filenames to a JSON file\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(filenames, f, indent=4)\n",
    "\n",
    "    print(f\"Saved {len(filenames)} filenames to {output_file}\")\n",
    "\n",
    "def get_common_subjects(folder1, folder2):\n",
    "    \"\"\"\n",
    "    Finds common subjects between two folders based on filenames.\n",
    "\n",
    "    Args:\n",
    "        folder1 (str): Path to the first folder.\n",
    "        folder2 (str): Path to the second folder.\n",
    "\n",
    "    Returns:\n",
    "        list: List of common subjects.\n",
    "    \"\"\"\n",
    "\n",
    "    files1 = set([f.split('_')[0] for f in os.listdir(folder1) if f.endswith('.set')])\n",
    "    files2 = set([f.split('_')[1] for f in os.listdir(folder2) if f.endswith('.set')])\n",
    "    print(len(files1), len(files2))\n",
    "    common_subjects = list(files1.intersection(files2))\n",
    "    return common_subjects\n",
    "\n",
    "def split_subjects_into_groups(subjects, num_groups):\n",
    "    \"\"\"\n",
    "    Splits subjects into a specified number of random groups.\n",
    "\n",
    "    Args:\n",
    "        subjects (list): List of subject filenames.\n",
    "        num_groups (int): Number of groups to split into.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary where keys are group indices and values are lists of subjects.\n",
    "    \"\"\"\n",
    "    random.shuffle(subjects)\n",
    "    groups = {i: [] for i in range(num_groups)}\n",
    "    for idx, subject in enumerate(subjects):\n",
    "        group_idx = idx % num_groups\n",
    "        groups[group_idx].append(subject)\n",
    "    return groups\n",
    "\n",
    "# Example usage\n",
    "folder2 = \"G:\\\\共用雲端硬碟\\\\CNElab_黎承宣&賴璁毅_EEG_ROI\\\\A.Dataset\\\\processed_setfile\"\n",
    "folder1 = \"G:\\\\共用雲端硬碟\\\\CNElab_黎承宣&賴璁毅_EEG_ROI\\\\A.Dataset\\\\setfile\"\n",
    "output_file = \"common_subjects.json\"\n",
    "num_groups = 20\n",
    "\n",
    "# Find common subjects\n",
    "common_subjects = get_common_subjects(folder1, folder2)\n",
    "\n",
    "# Save common subjects to a file\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(common_subjects, f, indent=4)\n",
    "print(f\"Saved {len(common_subjects)} common subjects to {output_file}\")\n",
    "\n",
    "# Split common subjects into groups\n",
    "groups = split_subjects_into_groups(common_subjects, num_groups)\n",
    "group_file = \"subject_groups.json\"\n",
    "with open(group_file, 'w') as f:\n",
    "    json.dump(groups, f, indent=4)\n",
    "print(f\"Saved subject groups to {group_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "轉換結果為字典：\n",
      "{'0_ICA_DLtrain': [], '1_ICA_DLtrain': [], '2_ICA_DLtrain': [], '3_ICA_DLtrain': [49, 87], '4_ICA_DLtrain': [], '5_ICA_DLtrain': [], '6_ICA_DLtrain': [], '7_ICA_DLtrain': [39, 81], '8_ICA_DLtrain': [42, 82], '9_ICA_DLtrain': [], '10_ICA_DLtrain': [], '11_ICA_DLtrain': [], '12_ICA_DLtrain': [39, 78], '13_ICA_DLtrain': [], '14_ICA_DLtrain': [], '15_ICA_DLtrain': [], '16_ICA_DLtrain': [], '17_ICA_DLtrain': [], '18_ICA_DLtrain': [], '19_ICA_DLtrain': [39, 79], '20_ICA_DLtrain': [39, 78], '21_ICA_DLtrain': [], '22_ICA_DLtrain': [], '23_ICA_DLtrain': [41, 81], '24_ICA_DLtrain': [], '25_ICA_DLtrain': [52, 91], '26_ICA_DLtrain': [], '27_ICA_DLtrain': [40, 79], '28_ICA_DLtrain': [40, 85], '29_ICA_DLtrain': [38, 79], '30_ICA_DLtrain': [44, 83], '31_ICA_DLtrain': [], '32_ICA_DLtrain': [], '33_ICA_DLtrain': [], '34_ICA_DLtrain': [40, 77], '35_ICA_DLtrain': [39, 70], '36_ICA_DLtrain': [], '37_ICA_DLtrain': [], '38_ICA_DLtrain': [40, 81], '39_ICA_DLtrain': [], '40_ICA_DLtrain': [], '41_ICA_DLtrain': [], '42_ICA_DLtrain': [], '43_ICA_DLtrain': [], '44_ICA_DLtrain': [], '45_ICA_DLtrain': [], '46_ICA_DLtrain': [], '47_ICA_DLtrain': [], '48_ICA_DLtrain': [40, 79], '49_ICA_DLtrain': [40, 78], '50_ICA_DLtrain': [], '51_ICA_DLtrain': [], '52_ICA_DLtrain': [], '53_ICA_DLtrain': [], '54_ICA_DLtrain': [], '55_ICA_DLtrain': [], '56_ICA_DLtrain': [], '57_ICA_DLtrain': [], '58_ICA_DLtrain': [43, 82], '59_ICA_DLtrain': [], '60_ICA_DLtrain': [], '61_ICA_DLtrain': [], '62_ICA_DLtrain': [], '63_ICA_DLtrain': [], '64_ICA_DLtrain': [], '65_ICA_DLtrain': [], '66_ICA_DLtrain': [41, 83], '67_ICA_DLtrain': [], '68_ICA_DLtrain': [], '69_ICA_DLtrain': [], '70_ICA_DLtrain': [], '71_ICA_DLtrain': [], '72_ICA_DLtrain': [39, 86], '73_ICA_DLtrain': [], '74_ICA_DLtrain': [], '75_ICA_DLtrain': [40, 80], '76_ICA_DLtrain': [39, 81], '77_ICA_DLtrain': []}\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "file_path = \"G:\\\\共用雲端硬碟\\\\CNElab_陳昱祺\\\\source localization\\\\test_data\\\\roi_removal_segment.txt\"\n",
    "\n",
    "def txt_to_dict_with_list(txt_file):\n",
    "    try:\n",
    "        with open(txt_file, \"r\", encoding=\"utf-8\") as file:\n",
    "            lines = file.readlines()\n",
    "        \n",
    "        result = {}\n",
    "        for line in lines:\n",
    "            line = line.strip()  # 移除空白與換行\n",
    "            if not line:  # 跳過空行\n",
    "                continue\n",
    "            parts = line.split(\",\")\n",
    "            filename = parts[0].strip(\".set\")\n",
    "            if len(parts) > 1:\n",
    "                # 將 index 切割為 list\n",
    "                index = [int(x) for x in parts[1].strip().split()]\n",
    "            else:\n",
    "                index = None\n",
    "            result[filename] = index\n",
    "\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"發生錯誤: {e}\")\n",
    "        return None\n",
    "\n",
    "# 主程式\n",
    "data_dict = txt_to_dict_with_list(file_path)\n",
    "\n",
    "# 打印結果\n",
    "if data_dict:\n",
    "    print(\"轉換結果為字典：\")\n",
    "    print(data_dict)\n",
    "\n",
    "if 87 in data_dict[\"3_ICA_DLtrain\"]:\n",
    "    print(\"49\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingface",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
