{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "roi_folder = \"G:\\\\共用雲端硬碟\\\\CNElab_陳昱祺\\\\source localization\\\\test_data\\\\ROI\\\\Desikan_Kilianny_with_3pca\"\n",
    "eeg_folder = \"G:\\\\共用雲端硬碟\\\\CNElab_陳昱祺\\\\source localization\\\\test_data\\\\ROI\\\\Desikan_Kilianny_with_3pca\"\n",
    "index_data = {}\n",
    "# Modify train_dataset and test_eval as per the new requirement\n",
    "index_data[\"train_dataset\"] = [str(i) for i in range(1, 400)]\n",
    "index_data[\"test_eval\"] = [str(i) for i in range(401, 499)]\n",
    "\n",
    "# Write the updated data to a JSON file\n",
    "with open(\"subject_groups.json\", \"w\") as json_file:\n",
    "    json.dump(index_data, json_file, indent=4)\n",
    "file_status = {}\n",
    "for subject in index_data[\"train_dataset\"]:\n",
    "    roi_path = os.path.join(roi_folder, f\"processed_{subject}_ICA_DLtrain.set\")\n",
    "    eeg_path = os.path.join(eeg_folder, f\"processed_{subject}_ICA_DLtrain.set\")\n",
    "\n",
    "    roi_exists = os.path.exists(roi_path)\n",
    "    eeg_exists = os.path.exists(eeg_path)\n",
    "\n",
    "    file_status[subject] = {\n",
    "        \"roi_exists\": roi_exists,\n",
    "        \"eeg_exists\": eeg_exists\n",
    "    }\n",
    "\n",
    "    if roi_exists == False or eeg_exists == False:\n",
    "        print(f\"{subject}: ROI exists: {roi_exists}, EEG exists: {eeg_exists}\")\n",
    "\n",
    "file_status = {}\n",
    "for subject in index_data[\"test_eval\"]:\n",
    "    roi_path = os.path.join(roi_folder, f\"processed_{subject}_ICA_DLtrain.set\")\n",
    "    eeg_path = os.path.join(eeg_folder, f\"processed_{subject}_ICA_DLtrain.set\")\n",
    "\n",
    "    roi_exists = os.path.exists(roi_path)\n",
    "    eeg_exists = os.path.exists(eeg_path)\n",
    "\n",
    "    file_status[subject] = {\n",
    "        \"roi_exists\": roi_exists,\n",
    "        \"eeg_exists\": eeg_exists\n",
    "    }\n",
    "\n",
    "    if roi_exists == False or eeg_exists == False:\n",
    "        print(f\"{subject}: ROI exists: {roi_exists}, EEG exists: {eeg_exists}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pymatreader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, './Dataloader')\n",
    "from SLT_dataloader import EEGROIDataset, SignalDataCollator, EEGROI_fft_Dataset\n",
    "\n",
    "# Usage example\n",
    "roi_folder = \"G:\\\\共用雲端硬碟\\\\CNElab_陳昱祺\\\\source localization\\\\test_data\\\\ROI\\\\Desikan_Kilianny_with_3pca\"\n",
    "eeg_folder = \"G:\\\\共用雲端硬碟\\\\CNElab_陳昱祺\\\\source localization\\\\test_data\\\\ROI\\\\Desikan_Kilianny_with_3pca\"\n",
    "group_file = \"subject_groups.json\"\n",
    "\n",
    "# Create dataset\n",
    "train_dataset = EEGROI_fft_Dataset(roi_folder, eeg_folder, group_file, \"test\")\n",
    "print(f\"Total dataset size: {len(train_dataset)}\")\n",
    "# Create dataset\n",
    "# test_dataset = EEGROIDataset(roi_folder, eeg_folder, group_file, \"test_dataset\")\n",
    "# print(f\"Total dataset size: {len(test_dataset)}\")\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "\n",
    "# 產生模擬 FFT 數據 (30 通道, 51 頻率點)\n",
    "np.random.seed(42)\n",
    "fft_data = np.random.rand(30, 51)  # 假設這是 FFT 結果\n",
    "# fft_data = train_dataset.__getitem__(0)['src'].numpy()\n",
    "# print(fft_data[0])\n",
    "\n",
    "# 頻率軸 (0~50 Hz)\n",
    "freqs = np.linspace(0, 50, 51)\n",
    "\n",
    "# 畫圖\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i in range(30):\n",
    "    plt.plot(freqs, fft_data[i], label=f\"Ch {i+1}\", alpha=0.6)\n",
    "\n",
    "plt.xlabel(\"Frequency (Hz)\")\n",
    "plt.ylabel(\"Power\")\n",
    "plt.title(\"EEG Power Spectrum (30 channels)\")\n",
    "plt.legend(loc=\"upper right\", bbox_to_anchor=(1.2, 1), fontsize=8)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import mne \n",
    "\n",
    "file_roi = \"G:\\\\共用雲端硬碟\\\\CNElab_黎承宣&賴璁毅_EEG_ROI\\\\A.Dataset\\\\processed_setfile\\\\processed_0_ICA_DLtrain.set\"\n",
    "file_eeg = \"G:\\\\共用雲端硬碟\\\\CNElab_黎承宣&賴璁毅_EEG_ROI\\\\A.Dataset\\\\setfile\\\\0_ICA_DLtrain.set\"\n",
    "\n",
    "with h5py.File(file_roi, 'r') as f:\n",
    "    if 'roi' in f:\n",
    "        ROI = f['roi']['source_voxel_data'][:]\n",
    "        print(ROI.shape)\n",
    "\n",
    "EEG = mne.io.read_raw_eeglab(file_eeg, preload=True)\n",
    "print(EEG.info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "import mne\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "roi_folder = \"G:\\\\共用雲端硬碟\\\\CNElab_黎承宣&賴璁毅_EEG_ROI\\\\A.Dataset\\\\processed_setfile\"\n",
    "eeg_folder = \"G:\\\\共用雲端硬碟\\\\CNElab_黎承宣&賴璁毅_EEG_ROI\\\\A.Dataset\\\\setfile\"\n",
    "roi_folder_ls = [f.split('_')[1] for f in os.listdir(roi_folder) if f.endswith('.set')]\n",
    "\n",
    "shape_list = []\n",
    "\n",
    "for subject in roi_folder_ls:\n",
    "    roi_path = os.path.join(roi_folder, f\"processed_{subject}_ICA_DLtrain.set\")\n",
    "    eeg_path = os.path.join(eeg_folder, f\"{subject}_ICA_DLtrain.set\")\n",
    "    # Load ROI data\n",
    "    with h5py.File(roi_path, 'r') as f:\n",
    "        if 'roi' in f:\n",
    "            roi_data = f['roi']['source_voxel_data'][:]\n",
    "            print(roi_data.shape)\n",
    "\n",
    "    # Load EEG data\n",
    "    eeg_data = mne.io.read_raw_eeglab(eeg_path, preload=True).get_data()\n",
    "    print(eeg_data.shape)\n",
    "    shape_list.append((roi_data.shape, eeg_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save File Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "\n",
    "def save_filenames_to_file(folder_path, output_file):\n",
    "    \"\"\"\n",
    "    Reads all filenames in a folder and saves them to a specified file.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): Path to the folder containing files.\n",
    "        output_file (str): Path to the output file to save filenames.\n",
    "    \"\"\"\n",
    "    # Get all filenames in the folder\n",
    "    filenames = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "\n",
    "    # Save filenames to a JSON file\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(filenames, f, indent=4)\n",
    "\n",
    "    print(f\"Saved {len(filenames)} filenames to {output_file}\")\n",
    "\n",
    "def get_common_subjects(folder1, folder2):\n",
    "    \"\"\"\n",
    "    Finds common subjects between two folders based on filenames.\n",
    "\n",
    "    Args:\n",
    "        folder1 (str): Path to the first folder.\n",
    "        folder2 (str): Path to the second folder.\n",
    "\n",
    "    Returns:\n",
    "        list: List of common subjects.\n",
    "    \"\"\"\n",
    "\n",
    "    files1 = set([f.split('_')[0] for f in os.listdir(folder1) if f.endswith('.set')])\n",
    "    files2 = set([f.split('_')[1] for f in os.listdir(folder2) if f.endswith('.set')])\n",
    "    print(len(files1), len(files2))\n",
    "    common_subjects = list(files1.intersection(files2))\n",
    "    return common_subjects\n",
    "\n",
    "def split_subjects_into_groups(subjects, num_groups):\n",
    "    \"\"\"\n",
    "    Splits subjects into a specified number of random groups.\n",
    "\n",
    "    Args:\n",
    "        subjects (list): List of subject filenames.\n",
    "        num_groups (int): Number of groups to split into.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary where keys are group indices and values are lists of subjects.\n",
    "    \"\"\"\n",
    "    random.shuffle(subjects)\n",
    "    groups = {i: [] for i in range(num_groups)}\n",
    "    for idx, subject in enumerate(subjects):\n",
    "        group_idx = idx % num_groups\n",
    "        groups[group_idx].append(subject)\n",
    "    return groups\n",
    "\n",
    "# Example usage\n",
    "folder2 = \"G:\\\\共用雲端硬碟\\\\CNElab_黎承宣&賴璁毅_EEG_ROI\\\\A.Dataset\\\\processed_setfile\"\n",
    "folder1 = \"G:\\\\共用雲端硬碟\\\\CNElab_黎承宣&賴璁毅_EEG_ROI\\\\A.Dataset\\\\setfile\"\n",
    "output_file = \"common_subjects.json\"\n",
    "num_groups = 20\n",
    "\n",
    "# Find common subjects\n",
    "common_subjects = get_common_subjects(folder1, folder2)\n",
    "\n",
    "# Save common subjects to a file\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(common_subjects, f, indent=4)\n",
    "print(f\"Saved {len(common_subjects)} common subjects to {output_file}\")\n",
    "\n",
    "# Split common subjects into groups\n",
    "groups = split_subjects_into_groups(common_subjects, num_groups)\n",
    "group_file = \"subject_groups.json\"\n",
    "with open(group_file, 'w') as f:\n",
    "    json.dump(groups, f, indent=4)\n",
    "print(f\"Saved subject groups to {group_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "file_path = \"G:\\\\共用雲端硬碟\\\\CNElab_陳昱祺\\\\source localization\\\\test_data\\\\roi_removal_segment.txt\"\n",
    "\n",
    "def txt_to_dict_with_list(txt_file):\n",
    "    try:\n",
    "        with open(txt_file, \"r\", encoding=\"utf-8\") as file:\n",
    "            lines = file.readlines()\n",
    "        \n",
    "        result = {}\n",
    "        for line in lines:\n",
    "            line = line.strip()  # 移除空白與換行\n",
    "            if not line:  # 跳過空行\n",
    "                continue\n",
    "            parts = line.split(\",\")\n",
    "            filename = parts[0].strip(\".set\")\n",
    "            if len(parts) > 1:\n",
    "                # 將 index 切割為 list\n",
    "                index = [int(x) for x in parts[1].strip().split()]\n",
    "            else:\n",
    "                index = None\n",
    "            result[filename] = index\n",
    "\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"發生錯誤: {e}\")\n",
    "        return None\n",
    "\n",
    "# 主程式\n",
    "data_dict = txt_to_dict_with_list(file_path)\n",
    "\n",
    "# 打印結果\n",
    "if data_dict:\n",
    "    print(\"轉換結果為字典：\")\n",
    "    print(data_dict)\n",
    "\n",
    "if 87 in data_dict[\"3_ICA_DLtrain\"]:\n",
    "    print(\"49\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy data storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mne\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "data_root = \"G:\\\\共用雲端硬碟\\\\CNElab_陳昱祺\\\\source localization\\\\test_data\\\\ROI\\\\Desikan_Kilianny_with_3pca\"\n",
    "save_root = \"G:\\\\共用雲端硬碟\\\\CNElab_陳昱祺\\\\source localization\\\\test_data\\\\ROI\\\\Desikan_Kilianny_with_3pca\"\n",
    "os.makedirs(save_root, exist_ok=True)\n",
    "\n",
    "subjects = range(1,510)\n",
    "\n",
    "for subject in subjects:\n",
    "    roi_path = os.path.join(data_root, f\"processed_{subject}_ICA_DLtrain.set\")\n",
    "    # roi_path = os.path.join(data_root, f\"processed_{subject}_ICA_DLtrain.fdt\")\n",
    "\n",
    "    # 轉換 ROI\n",
    "    with h5py.File(roi_path, 'r') as f:\n",
    "        print(f.keys())\n",
    "        print(f['data'][:])\n",
    "\n",
    "    # # 轉換 EEG\n",
    "    # raw = mne.io.read_raw_eeglab(roi_path, preload=True)\n",
    "    # eeg_data = raw.get_data()  # (channels, time)\n",
    "    # print(f\"EEG shape: {eeg_data.shape}\")\n",
    "    # print(eeg_data)\n",
    "    # np.save(os.path.join(save_root, f\"{subject}_eeg.npy\"), eeg_data)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_root = \"G:\\\\共用雲端硬碟\\\\CNElab_陳昱祺\\\\source localization\\\\test_data\\\\ROI\\\\Desikan_Kilianny_with_3pca\"\n",
    "subjects = range(0,10)\n",
    "for subject in subjects:\n",
    "    roi_path = os.path.join(data_root, f\"{subject}_roi.npy\")\n",
    "    eeg_path = os.path.join(data_root, f\"{subject}_eeg.npy\")\n",
    "\n",
    "    # 讀取 ROI & EEG\n",
    "    roi_data = np.load(roi_path)\n",
    "    eeg_data = np.load(eeg_path)\n",
    "\n",
    "    assert roi_data.shape[1] == 200, f\"Unexpected ROI shape: {roi_data.shape}\"\n",
    "    assert eeg_data.shape[0] == 30, f\"Unexpected EEG shape: {eeg_data.shape}\"\n",
    "\n",
    "    # 直接處理資料\n",
    "    # _process_subject_data(roi_data, eeg_data, subject_name=f\"{subject}_ICA_DLtrain\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate Dataloader Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import mne\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def channel_mapping(_64_ch_names, _32_ch_names, eeg_data):\n",
    "    _32_eeg_data = []\n",
    "    \n",
    "    for ch in _32_ch_names:\n",
    "        current_idx = _64_ch_names.index(ch)  # 找到 64 通道中的對應索引\n",
    "        _32_eeg_data.append(eeg_data[current_idx])  # 提取相應數據\n",
    "    \n",
    "    return np.array(_32_eeg_data)  # 轉為 NumPy 陣列\n",
    "\n",
    "def print_channel(_64_ch_names, _32_ch_names, _64_eeg_data, _32_eeg_data):\n",
    "    flag = True\n",
    "    for ind, chn in enumerate(_32_ch_names):\n",
    "        mapping_index = _64_ch_names.index(chn)\n",
    "        # print(ind, chn, mapping_index, len(_64_eeg_data))\n",
    "        if _32_eeg_data[ind].sum() != _64_eeg_data[mapping_index].sum():\n",
    "            flag = False\n",
    "\n",
    "    return flag\n",
    "\n",
    "data_path = \"G:\\\\共用雲端硬碟\\\\CNElab_陳昱祺\\\\source localization\\\\simulate_data\\\\dataset_100_1000000.0_20250322_152651\\\\\"\n",
    "\n",
    "# 讀取全部資料\n",
    "all_eeg_data = np.load(os.path.join(data_path, \"all_eeg_data.npy\"), allow_pickle=True)\n",
    "all_source_data = np.load(os.path.join(data_path, \"all_source_data.npy\"), allow_pickle=True)\n",
    "\n",
    "_EEG = torch.tensor(np.stack(all_eeg_data), dtype=torch.float32)  # (N, 64, 51)\n",
    "ROI = torch.tensor(np.stack(all_source_data), dtype=torch.float32)  # (N, 204, 51)\n",
    "\n",
    "# 建立 channel map (只做一次)\n",
    "ch_names_64 = mne.io.read_raw('G:\\\\共用雲端硬碟\\\\CNElab_陳昱祺\\\\source localization\\\\test_raw.fif', verbose='Warning').resample(100).info['ch_names']\n",
    "ch_names_32 = ['Fp1', 'Fpz', 'Fp2', 'F7', 'F3', 'Fz', 'F4', 'F8', 'FC5', 'FC1', 'FC2', 'FC6', \n",
    "                'T7', 'C3', 'Cz', 'C4', 'T8', 'CP5', 'CP1', 'CP2', 'CP6', 'P7', 'P3', \n",
    "                'Pz', 'P4', 'P8', 'POz', 'O1', 'Oz', 'O2']\n",
    "\n",
    "ch_idx_map = [ch_names_64.index(ch) for ch in ch_names_32]\n",
    "print(f\"EEG = {_EEG.shape}\")\n",
    "\n",
    "# 選出 32 channels\n",
    "EEG = _EEG[:, ch_idx_map, :]  # (N, 30, 51)\n",
    "\n",
    "print(f\"Preprocessing complete. Total valid samples: {_EEG.shape}\")\n",
    "print(f\"Preprocessing complete. Total valid samples: {EEG.shape}\")\n",
    "\n",
    "flag_ = True\n",
    "for idx, _eeg_ in enumerate(EEG):\n",
    "\n",
    "    print(_eeg_.shape)\n",
    "\n",
    "    temp_flag = print_channel(ch_names_64, ch_names_32, _EEG[idx,:,:], _eeg_)\n",
    "    print(f\"Data:{idx} is {temp_flag}\")\n",
    "    flag_ = flag_ & temp_flag\n",
    "\n",
    "    if idx == 20:\n",
    "        break\n",
    "\n",
    "print(flag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# \"../../source localization/simulate_data/dataset_25000_1000000.0_20250321_194857/\"\n",
    "\n",
    "source_dataset_path = \"../../source localization/simulate_data/dataset_25000_1000000.0_20250321_194857/\"\n",
    "destination_dataset_path = \"../../source localization/simulate_data/dataset_25000_1000000.0_20250321_194857/train_dataset/\"\n",
    "lsdir = os.listdir(source_dataset_path)\n",
    "\n",
    "# 過濾出以 \"eeg_data_\" 開頭的檔案\n",
    "eeg_files = [file for file in lsdir if file.startswith(\"eeg_data_\")]\n",
    "\n",
    "max_idx = 3500\n",
    "for idx, eeg_path in enumerate(eeg_files):\n",
    "    source_path = eeg_path.replace(\"eeg\", \"source\")\n",
    "    os.replace(source_dataset_path + eeg_path, destination_dataset_path + eeg_path)\n",
    "    os.replace(source_dataset_path + source_path, destination_dataset_path + source_path)\n",
    "\n",
    "    # if idx == max_idx:\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, './Dataloader')\n",
    "from SLT_dataloader import EEGROIDataset, SignalDataCollator, EEGROI_fft_Dataset, EEGROI_Power_Dataset\n",
    "\n",
    "data_path = \"G:\\共用雲端硬碟\\CNElab_陳昱祺\\source localization\\simulate_data\\\\dataset_1000_1000000.0_20250322_225032\\\\test_dataset\\\\\"\n",
    "\n",
    "dataset = EEGROI_Power_Dataset(data_path)\n",
    "\n",
    "print(dataset.__getitem__(0)['src'].shape)\n",
    "print(dataset.__getitem__(0)['label'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "folders = [\n",
    "    \"G:\\\\共用雲端硬碟\\\\CNElab_陳昱祺\\\\source localization\\\\simulate_data\\\\dataset_1000_1_20250323_150519\",\n",
    "    \"G:\\\\共用雲端硬碟\\\\CNElab_陳昱祺\\\\source localization\\\\simulate_data\\\\dataset_1000_1000000.0_20250322_225032\",\n",
    "    \"G:\\\\共用雲端硬碟\\\\CNElab_陳昱祺\\\\source localization\\\\simulate_data\\\\dataset_1000_10_20250324_031827\",\n",
    "]\n",
    "\n",
    "for folder_path in folders:\n",
    "    folder_path = os.path.normpath(folder_path)  # 正規化路徑，移除末尾斜線\n",
    "    folder_name = os.path.basename(folder_path)\n",
    "    \n",
    "    print(f\"Folder name: {folder_name}\")  # 確認你拿到的名稱是對的\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        if os.path.isdir(file_path):\n",
    "            continue\n",
    "\n",
    "        if filename.startswith(folder_name + \"_\"):\n",
    "            continue\n",
    "\n",
    "        new_filename = f\"{folder_name}_{filename}\"\n",
    "        new_file_path = os.path.join(folder_path, new_filename)\n",
    "\n",
    "        os.rename(file_path, new_file_path)\n",
    "        print(f\"Renamed: {filename} -> {new_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 取得一筆資料\n",
    "sample = dataset.__getitem__(0)\n",
    "eeg_power = sample['src']      # [30, 51]\n",
    "source_power = sample['label'] # [204, 51]\n",
    "\n",
    "### 畫 EEG Power ###\n",
    "eeg_ymin = eeg_power.min().item()\n",
    "eeg_ymax = eeg_power.max().item()\n",
    "\n",
    "fig, axs = plt.subplots(6, 5, figsize=(20, 12))\n",
    "fig.suptitle(\"EEG Power Spectrum (30 ROIs)\", fontsize=16)\n",
    "\n",
    "for i in range(30):\n",
    "    row, col = divmod(i, 5)\n",
    "    ax = axs[row, col]\n",
    "    ax.plot(np.arange(eeg_power.shape[1]), eeg_power[i].numpy())\n",
    "    ax.set_ylim([eeg_ymin, eeg_ymax])\n",
    "    ax.set_title(f'ROI {i}')\n",
    "    ax.set_xticks([0, 25, 50])\n",
    "    ax.set_xlabel(\"Freq bin\")\n",
    "    ax.set_ylabel(\"Power\")\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()\n",
    "\n",
    "### 畫 Source Power ###\n",
    "src_ymin = source_power.min().item()\n",
    "src_ymax = source_power.max().item()\n",
    "\n",
    "n_sources = source_power.shape[0]\n",
    "nrows = ncols = int(np.ceil(np.sqrt(n_sources)))  # 自動決定最接近平方的排列方式\n",
    "\n",
    "fig, axs = plt.subplots(nrows, ncols, figsize=(24, 24))\n",
    "fig.suptitle(\"Source Power Spectrum (204 Sources)\", fontsize=18)\n",
    "\n",
    "for i in range(n_sources):\n",
    "    row, col = divmod(i, ncols)\n",
    "    ax = axs[row, col]\n",
    "    ax.plot(np.arange(source_power.shape[1]), source_power[i].numpy())\n",
    "    ax.set_ylim([src_ymin, src_ymax])\n",
    "    ax.set_title(f'Source {i}', fontsize=8)\n",
    "    ax.set_xticks([0, 25, 50])\n",
    "    ax.tick_params(labelsize=6)\n",
    "\n",
    "# 將多餘的 subplot 清除\n",
    "for j in range(n_sources, nrows * ncols):\n",
    "    fig.delaxes(axs[j // ncols, j % ncols])\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Dataset Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, './Dataloader')\n",
    "from SLT_dataloader import EEGROIDataset, SignalDataCollator, EEGROI_fft_Dataset, EEGROI_Power_Dataset, EEGROI_Merge_Dataset\n",
    "\n",
    "data_path_1 = \"G:\\共用雲端硬碟\\CNElab_陳昱祺\\source localization\\simulate_data\\\\dataset_seedsource_2000_1000000.0_20250404_215543\\\\\"\n",
    "data_path_2 = \"G:\\共用雲端硬碟\\CNElab_陳昱祺\\source localization\\simulate_data\\\\dataset_seedsource_2000_10.0_20250403_161648\\\\\"\n",
    "data_path_3 = \"G:\\共用雲端硬碟\\CNElab_陳昱祺\\source localization\\simulate_data\\\\dataset_seedsource_2000_1.0_20250403_161635\\\\\"\n",
    "test_path = \"G:\\\\共用雲端硬碟\\\\CNElab_陳昱祺\\\\source localization\\\\test_data\\\\ROI\\\\Desikan_Kilianny_with_3pca\\\\\"\n",
    "group_file = \"./subject_groups.json\"\n",
    "\n",
    "\n",
    "dataset_1 = EEGROI_Power_Dataset(data_path_1)\n",
    "dataset_2 = EEGROI_Power_Dataset(data_path_2)\n",
    "dataset_3 = EEGROI_Power_Dataset(data_path_3)\n",
    "dataset_4 = EEGROI_fft_Dataset(test_path, test_path, group_file, \"eval_dataset\")\n",
    "\n",
    "merge_dataset = EEGROI_Merge_Dataset([dataset_1, dataset_2, dataset_3, dataset_4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask Data Collector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SLT_dataloader import RandonMaskDataCollator\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "\n",
    "class FakeEEGDataset(Dataset):\n",
    "    def __init__(self, num_samples=3):\n",
    "        self.num_samples = num_samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src = torch.randn(204, 100)  # 模擬你的EEG輸入\n",
    "        label = src.clone()          # tgt 是 copy（真實世界可以不一樣）\n",
    "        return {\"src\": src, \"label\": label}\n",
    "    \n",
    "data_collator = RandonMaskDataCollator(mask_prob=0.15)\n",
    "\n",
    "dataset = FakeEEGDataset()\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=2, collate_fn=data_collator)\n",
    "\n",
    "for batch in loader:\n",
    "    print(\"src shape:\", batch[\"src\"].shape)\n",
    "    print(\"tgt shape:\", batch[\"tgt\"].shape)\n",
    "    print(\"tgt_mask shape:\", batch[\"tgt_token_mask\"].shape)\n",
    "    print(\"masked tokens (per sample):\", batch[\"tgt_token_mask\"].sum(dim=1))\n",
    "    \n",
    "    # 示範一個 mask 的效果\n",
    "    i = 0  # 看第一個 sample\n",
    "    mask = batch[\"tgt_token_mask\"][i]               # shape: (204,)\n",
    "    tgt = batch[\"tgt\"][i]                     # shape: (204, 100)\n",
    "    print(f\"\\nSample {i} -- Masked {mask.sum().item()} tokens\")\n",
    "    \n",
    "    # 你可以選擇畫圖或手動觀察數值\n",
    "    print(\"Masked segment [index 5]:\")\n",
    "    print(\"mask =\", mask[5].item())\n",
    "    print(\"tgt[5] =\", tgt[5])\n",
    "    break  # 只測一個 batch 就好\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEG Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EEG Dataset Mask Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SLT_dataloader import RandonMaskDataCollator, RandonMaskEEGDataCollator, EEG_Dataset, EEGDatasetFromNPY, RandonMaskShuffleEEGDataCollator, TshingHwa_Dataset\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "\n",
    "train_data_path = f\"G:\\\\共用雲端硬碟\\\\CNElab_陳昱祺\\\\source localization\\\\test_data\\\\ROI\\\\EEG\\\\train_dataset.npy\"\n",
    "train_data_list = [train_data_path]\n",
    "train_dataset = EEGDatasetFromNPY(train_data_list)\n",
    "\n",
    "# path = \"G:\\\\共用雲端硬碟\\\\CNElab_陳昱祺\\\\source localization\\\\test_data\\\\tshinghwa\\\\train_dataset.npy\"\n",
    "# list = [path]\n",
    "# train_dataset = TshingHwa_Dataset(list)\n",
    "\n",
    "data_collator = RandonMaskShuffleEEGDataCollator(mask_prob=0.3)\n",
    "\n",
    "loader = DataLoader(train_dataset, batch_size=256, collate_fn=data_collator)\n",
    "\n",
    "\n",
    "for batch in loader:\n",
    "    print(\"src shape:\", batch[\"src\"].shape)\n",
    "    print(\"tgt shape:\", batch[\"tgt\"].shape)\n",
    "    print(\"montage shape:\", batch['montage'].shape)\n",
    "    print(\"tgt_mask shape:\", batch[\"tgt_token_mask\"].shape)\n",
    "    print(\"masked tokens (per sample):\", batch[\"tgt_token_mask\"].sum(dim=1))\n",
    "    \n",
    "    # 示範一個 mask 的效果\n",
    "    i = 0  # 看第一個 sample\n",
    "    mask = batch[\"tgt_token_mask\"][i]               # shape: (204,)\n",
    "    tgt = batch[\"tgt\"][i]                     # shape: (204, 100)\n",
    "    print(f\"\\nSample {i} -- Masked {mask.sum().item()} tokens\")\n",
    "    \n",
    "    # 你可以選擇畫圖或手動觀察數值\n",
    "    print(\"Masked segment [index 5]:\")\n",
    "    print(\"postition\", batch['montage'][5])\n",
    "    print(\"mask =\", mask[5].item())\n",
    "    print(\"tgt[5] =\", tgt[5])\n",
    "    break  # 只測一個 batch 就好\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EEG dataset save "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SLT_dataloader import RandonMaskDataCollator, EEG_Dataset\n",
    "eval_path =  \"G:\\\\共用雲端硬碟\\\\CNElab_陳昱祺\\\\source localization\\\\test_data\\\\ROI\\\\Desikan_Kilianny_with_3pca\\\\\"\n",
    "# Create dataset\n",
    "group_file = \"./subject_groups.json\"\n",
    "dataset = EEG_Dataset(eval_path, group_file, 'test_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'src': tensor([[-0.4476,  0.8865,  0.7947,  ..., -0.7424, -0.8432, -0.8584],\n",
       "         [ 0.6665,  5.7997,  1.0987,  ..., -0.7096, -0.8969, -0.9798],\n",
       "         [-0.5579, -0.5624,  1.5952,  ..., -0.9018, -0.9137, -0.9681],\n",
       "         ...,\n",
       "         [ 2.5453,  3.4630,  2.5444,  ..., -0.2876, -0.5436, -0.2311],\n",
       "         [ 1.5473,  1.7349,  7.7260,  ..., -0.0748, -0.5526, -0.6772],\n",
       "         [ 4.2734,  9.9639,  1.7922,  ..., -0.4624, -0.3945, -0.8557]]),\n",
       " 'montage': ['Fp1',\n",
       "  'Fp2',\n",
       "  'F7',\n",
       "  'F3',\n",
       "  'Fz',\n",
       "  'F4',\n",
       "  'F8',\n",
       "  'FT7',\n",
       "  'FC3',\n",
       "  'FCz',\n",
       "  'FC4',\n",
       "  'FT8',\n",
       "  'T3',\n",
       "  'C3',\n",
       "  'Cz',\n",
       "  'C4',\n",
       "  'T4',\n",
       "  'TP7',\n",
       "  'CP3',\n",
       "  'CPz',\n",
       "  'CP4',\n",
       "  'TP8',\n",
       "  'T5',\n",
       "  'P3',\n",
       "  'Pz',\n",
       "  'P4',\n",
       "  'T6',\n",
       "  'O1',\n",
       "  'Oz',\n",
       "  'O2']}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from SLT_dataloader import RandonMaskDataCollator, RandonMaskEEGDataCollator, EEG_Dataset, EEGDatasetFromNPY, RandonMaskShuffleEEGDataCollator, TshingHwa_Dataset, EEGROI_Merge_Dataset\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "train_data_path = f\"G:\\\\共用雲端硬碟\\\\CNElab_陳昱祺\\\\source localization\\\\test_data\\\\ROI\\\\EEG\\\\train_dataset.npy\"\n",
    "train_data_list = [train_data_path]\n",
    "train_2_dataset = EEGDatasetFromNPY(train_data_list)\n",
    "train_2_dataset.__getitem__(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TshingHwa Dataset Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SLT_dataloader import RandonMaskDataCollator, TshingHwa_Dataset\n",
    "path = \"G:\\\\共用雲端硬碟\\\\CNElab_陳昱祺\\\\source localization\\\\test_data\\\\tshinghwa\\\\train_dataset.npy\"\n",
    "# list = [path]\n",
    "# dataset = TshingHwa_Dataset(list)\n",
    "# dataset.__len__()\n",
    "# dataset.__getitem__(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SLT_dataloader import RandonMaskDataCollator, RandonMaskEEGDataCollator, EEG_Dataset, EEGDatasetFromNPY, RandonMaskShuffleEEGDataCollator, TshingHwa_Dataset, EEGROI_Merge_Dataset\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "\n",
    "train_data_path = f\"G:\\\\共用雲端硬碟\\\\CNElab_陳昱祺\\\\source localization\\\\test_data\\\\ROI\\\\EEG\\\\train_dataset.npy\"\n",
    "train_data_list = [train_data_path]\n",
    "train_2_dataset = EEGDatasetFromNPY(train_data_list)\n",
    "\n",
    "path = \"G:\\\\共用雲端硬碟\\\\CNElab_陳昱祺\\\\source localization\\\\test_data\\\\tshinghwa\\\\train_dataset.npy\"\n",
    "list = [path]\n",
    "train_1_dataset = TshingHwa_Dataset(list)\n",
    "\n",
    "merge_dataset = EEGROI_Merge_Dataset([train_1_dataset, train_2_dataset])\n",
    "# print(merge_dataset.__len__())\n",
    "# merge_dataset.__getitem__(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import mne\n",
    "\n",
    "# 先跑一個 batch\n",
    "collator = RandonMaskShuffleEEGDataCollator(mask_prob=0.3)\n",
    "loader = DataLoader(merge_dataset, batch_size=4, shuffle=True, collate_fn=collator)\n",
    "\n",
    "for batch in loader:\n",
    "    i = 0  # 第 i 個 sample\n",
    "    src = batch[\"src\"][i].squeeze(0).detach().cpu()  # (C, F)\n",
    "    tgt = batch[\"tgt\"][i].squeeze(0).detach().cpu()\n",
    "    label = batch[\"labels\"][i].squeeze(0).detach().cpu()\n",
    "    mask = batch[\"tgt_token_mask\"][i]  # (C,)\n",
    "    print(mask.shape)\n",
    "    valid_mask = batch[\"valid_channel_mask\"][i]  # (C,)\n",
    "    print(valid_mask.shape)\n",
    "    attn_mask = batch[\"src_mask\"][i]   # (C, C)\n",
    "    print(attn_mask.shape)\n",
    "\n",
    "    montage_name = batch['montage'][i]\n",
    "    print(len(montage_name), montage_name)\n",
    "    # 將 tensor 轉為 numpy 並確保 shape 正確\n",
    "    src_np = src.detach().cpu().numpy()       # (C, F)\n",
    "    mask_np = mask.detach().cpu().numpy()     # (C,)\n",
    "\n",
    "    # 取得被 mask 的 channel index\n",
    "    masked_indices = torch.where(mask)[0].tolist()\n",
    "\n",
    "    # 可視化\n",
    "    # plt.figure(figsize=(12, len(masked_indices) * 1.5))\n",
    "\n",
    "    # for i, ch_idx in enumerate(masked_indices):\n",
    "    #     plt.plot(src_np[ch_idx] + i * 10, label=montage_name[ch_idx])  # 加上 vertical offset 以避免重疊\n",
    "\n",
    "    # plt.xlabel(\"Time (sample)\")\n",
    "    # plt.ylabel(\"Amplitude + offset\")\n",
    "    # plt.title(\"Masked Channels (Only)\")\n",
    "    # plt.legend(loc=\"upper right\")\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "    \n",
    "    # effective_mask = mask & valid_mask  # (B, C)\n",
    "    # --- 可視化 Masked Channel ---\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Masked Channels (tgt_token_mask)\")\n",
    "    plt.imshow(mask.unsqueeze(0), cmap=\"gray\", aspect=\"auto\")\n",
    "    plt.yticks([])\n",
    "    plt.xlabel(\"Channel Index\")\n",
    "    plt.colorbar(label=\"Masked (1=True)\")\n",
    "\n",
    "    # --- 可視化 Attention Mask ---\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Attention Mask (src_mask)\")\n",
    "    sns.heatmap(attn_mask.float(), cmap=\"gray\", cbar=True)\n",
    "    plt.xlabel(\"Key Channel\")\n",
    "    plt.ylabel(\"Query Channel\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 畫圖：68 個 subplot，output vs ground truth\n",
    "    num_channels = tgt.shape[0]\n",
    "    num_cols = 5\n",
    "    num_rows = (num_channels + num_cols - 1) // num_cols\n",
    "\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(16, 3*num_rows), sharex=True, sharey=False)\n",
    "\n",
    "    for i in range(num_channels):\n",
    "        row, col = divmod(i, num_cols)\n",
    "        ax = axes[row, col] if num_rows > 1 else axes[col]\n",
    "        ax.plot(src[i], label='src', linestyle='-', linewidth=1)\n",
    "        ax.plot(tgt[i], label='tgt', linestyle='--', linewidth=1)\n",
    "        ax.plot(label[i], label='label', linestyle='-.', linewidth=1)\n",
    "        # ax.set_title(f'{montage_mask[i]}', fontsize=8)\n",
    "        ax.set_title(f'{i}', fontsize=8)\n",
    "        ax.tick_params(labelsize=6)\n",
    "\n",
    "    # 加 legend 只加一次\n",
    "    axes[0, 0].legend(fontsize=8)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingface",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
