{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SLT Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '314', '20']\n",
      "ROI Times: 302.0\n",
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\0_ICA_DLtrain.fdt\n",
      "Reading 0 ... 77496  =      0.000 ...   302.719 secs...\n",
      "Total Nan of the subject: 0\n",
      "ROI Times: 308.0\n",
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\1_ICA_DLtrain.fdt\n",
      "Reading 0 ... 78878  =      0.000 ...   308.117 secs...\n",
      "Total Nan of the subject: 0\n",
      "ROI Times: 300.0\n",
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\2_ICA_DLtrain.fdt\n",
      "Reading 0 ... 77004  =      0.000 ...   300.797 secs...\n",
      "Total Nan of the subject: 0\n",
      "ROI Times: 254.0\n",
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\3_ICA_DLtrain.fdt\n",
      "Reading 0 ... 66080  =      0.000 ...   258.125 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\共用雲端硬碟\\CNElab_陳昱祺\\multi-modal\\Dataloader\\SLT_dataloader.py:56: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  eeg_data = mne.io.read_raw_eeglab(eeg_path, preload=True).get_data()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Nan of the subject: 0\n",
      "ROI Times: 304.0\n",
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\4_ICA_DLtrain.fdt\n",
      "Reading 0 ... 78059  =      0.000 ...   304.918 secs...\n",
      "Total Nan of the subject: 0\n",
      "ROI Times: 302.0\n",
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\5_ICA_DLtrain.fdt\n",
      "Reading 0 ... 77393  =      0.000 ...   302.316 secs...\n",
      "Total Nan of the subject: 0\n",
      "ROI Times: 316.0\n",
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\6_ICA_DLtrain.fdt\n",
      "Reading 0 ... 81336  =      0.000 ...   317.719 secs...\n",
      "Total Nan of the subject: 0\n",
      "ROI Times: 234.0\n",
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\7_ICA_DLtrain.fdt\n",
      "Reading 0 ... 61092  =      0.000 ...   238.641 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\共用雲端硬碟\\CNElab_陳昱祺\\multi-modal\\Dataloader\\SLT_dataloader.py:56: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  eeg_data = mne.io.read_raw_eeglab(eeg_path, preload=True).get_data()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Nan of the subject: 0\n",
      "ROI Times: 238.0\n",
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\8_ICA_DLtrain.fdt\n",
      "Reading 0 ... 62045  =      0.000 ...   242.363 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\共用雲端硬碟\\CNElab_陳昱祺\\multi-modal\\Dataloader\\SLT_dataloader.py:56: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  eeg_data = mne.io.read_raw_eeglab(eeg_path, preload=True).get_data()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Nan of the subject: 0\n",
      "ROI Times: 314.0\n",
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\9_ICA_DLtrain.fdt\n",
      "Reading 0 ... 80629  =      0.000 ...   314.957 secs...\n",
      "Total Nan of the subject: 0\n",
      "ROI Times: 314.0\n",
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\10_ICA_DLtrain.fdt\n",
      "Reading 0 ... 80506  =      0.000 ...   314.477 secs...\n",
      "Total Nan of the subject: 0\n",
      "ROI Times: 300.0\n",
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\11_ICA_DLtrain.fdt\n",
      "Reading 0 ... 77199  =      0.000 ...   301.559 secs...\n",
      "Total Nan of the subject: 0\n",
      "ROI Times: 230.0\n",
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\12_ICA_DLtrain.fdt\n",
      "Reading 0 ... 60211  =      0.000 ...   235.199 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\共用雲端硬碟\\CNElab_陳昱祺\\multi-modal\\Dataloader\\SLT_dataloader.py:56: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  eeg_data = mne.io.read_raw_eeglab(eeg_path, preload=True).get_data()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Nan of the subject: 0\n",
      "ROI Times: 312.0\n",
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\13_ICA_DLtrain.fdt\n",
      "Reading 0 ... 79933  =      0.000 ...   312.238 secs...\n",
      "Total Nan of the subject: 0\n",
      "ROI Times: 302.0\n",
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\14_ICA_DLtrain.fdt\n",
      "Reading 0 ... 77527  =      0.000 ...   302.840 secs...\n",
      "Total Nan of the subject: 0\n",
      "ROI Times: 332.0\n",
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\15_ICA_DLtrain.fdt\n",
      "Reading 0 ... 85391  =      0.000 ...   333.559 secs...\n",
      "Total Nan of the subject: 0\n",
      "ROI Times: 310.0\n",
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\16_ICA_DLtrain.fdt\n",
      "Reading 0 ... 79851  =      0.000 ...   311.918 secs...\n",
      "Total Nan of the subject: 0\n",
      "ROI Times: 324.0\n",
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\17_ICA_DLtrain.fdt\n",
      "Reading 0 ... 82995  =      0.000 ...   324.199 secs...\n",
      "Total Nan of the subject: 0\n",
      "ROI Times: 312.0\n",
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\18_ICA_DLtrain.fdt\n",
      "Reading 0 ... 80015  =      0.000 ...   312.559 secs...\n",
      "Total Nan of the subject: 0\n",
      "ROI Times: 302.0\n",
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\314_ICA_DLtrain.fdt\n",
      "Reading 0 ... 77475  =      0.000 ...   302.637 secs...\n",
      "Total Nan of the subject: 0\n",
      "ROI Times: 228.0\n",
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\20_ICA_DLtrain.fdt\n",
      "Reading 0 ... 59536  =      0.000 ...   232.562 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\共用雲端硬碟\\CNElab_陳昱祺\\multi-modal\\Dataloader\\SLT_dataloader.py:56: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  eeg_data = mne.io.read_raw_eeglab(eeg_path, preload=True).get_data()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Nan of the subject: 0\n",
      "Total dataset size: 3069\n",
      "['49', '345', '364', '422', '90']\n",
      "ROI Times: 228.0\n",
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\49_ICA_DLtrain.fdt\n",
      "Reading 0 ... 59760  =      0.000 ...   233.438 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\共用雲端硬碟\\CNElab_陳昱祺\\multi-modal\\Dataloader\\SLT_dataloader.py:56: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  eeg_data = mne.io.read_raw_eeglab(eeg_path, preload=True).get_data()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Nan of the subject: 0\n",
      "ROI Times: 312.0\n",
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\345_ICA_DLtrain.fdt\n",
      "Reading 0 ... 80220  =      0.000 ...   313.359 secs...\n",
      "Total Nan of the subject: 0\n",
      "ROI Times: 300.0\n",
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\364_ICA_DLtrain.fdt\n",
      "Reading 0 ... 77168  =      0.000 ...   301.438 secs...\n",
      "Total Nan of the subject: 0\n",
      "ROI Times: 300.0\n",
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\422_ICA_DLtrain.fdt\n",
      "Reading 0 ... 76799  =      0.000 ...   299.996 secs...\n",
      "Total Nan of the subject: 0\n",
      "ROI Times: 228.0\n",
      "Reading G:\\共用雲端硬碟\\CNElab_黎承宣&賴璁毅_EEG_ROI\\A.Dataset\\setfile\\90_ICA_DLtrain.fdt\n",
      "Reading 0 ... 59464  =      0.000 ...   232.281 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\共用雲端硬碟\\CNElab_陳昱祺\\multi-modal\\Dataloader\\SLT_dataloader.py:56: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  eeg_data = mne.io.read_raw_eeglab(eeg_path, preload=True).get_data()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Nan of the subject: 0\n",
      "Total dataset size: 684\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, './Dataloader')\n",
    "from SLT_dataloader import EEGROIDataset, SignalDataCollator\n",
    "\n",
    "# Usage example\n",
    "roi_folder = \"G:\\\\共用雲端硬碟\\\\CNElab_黎承宣&賴璁毅_EEG_ROI\\\\A.Dataset\\\\processed_setfile\"\n",
    "eeg_folder = \"G:\\\\共用雲端硬碟\\\\CNElab_黎承宣&賴璁毅_EEG_ROI\\\\A.Dataset\\\\setfile\"\n",
    "group_file = \"./Dataloader/subject_groups.json\"\n",
    "\n",
    "# Create dataset\n",
    "train_dataset = EEGROIDataset(roi_folde0r, eeg_folder, group_file, \"train_dataset\")\n",
    "print(f\"Total dataset size: {len(train_dataset)}\")\n",
    "# Create dataset\n",
    "test_dataset = EEGROIDataset(roi_folder, eeg_folder, group_file, \"eval\")\n",
    "print(f\"Total dataset size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: Currently logged in as: richielp700 (richielp700-national-tsing-hua-university). Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>G:\\共用雲端硬碟\\CNElab_陳昱祺\\multi-modal\\wandb\\run-20241230_161846-12sf9q0m</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/richielp700-national-tsing-hua-university/huggingface/runs/12sf9q0m' target=\"_blank\">./results/20241230_161842_model_init_LR_05</a></strong> to <a href='https://wandb.ai/richielp700-national-tsing-hua-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/richielp700-national-tsing-hua-university/huggingface' target=\"_blank\">https://wandb.ai/richielp700-national-tsing-hua-university/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/richielp700-national-tsing-hua-university/huggingface/runs/12sf9q0m' target=\"_blank\">https://wandb.ai/richielp700-national-tsing-hua-university/huggingface/runs/12sf9q0m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2880' max='2880' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2880/2880 13:07:26, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.939900</td>\n",
       "      <td>1.936036</td>\n",
       "      <td>1.967581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>1.937600</td>\n",
       "      <td>1.936847</td>\n",
       "      <td>1.970164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>1.939900</td>\n",
       "      <td>1.933460</td>\n",
       "      <td>1.965250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>1.939700</td>\n",
       "      <td>1.938017</td>\n",
       "      <td>1.969725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.925400</td>\n",
       "      <td>1.937559</td>\n",
       "      <td>1.969669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>1.946500</td>\n",
       "      <td>1.934961</td>\n",
       "      <td>1.967475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>336</td>\n",
       "      <td>1.927400</td>\n",
       "      <td>1.932846</td>\n",
       "      <td>1.964924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>384</td>\n",
       "      <td>1.943300</td>\n",
       "      <td>1.935062</td>\n",
       "      <td>1.967464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>432</td>\n",
       "      <td>1.935700</td>\n",
       "      <td>1.933609</td>\n",
       "      <td>1.965299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>1.940100</td>\n",
       "      <td>1.934230</td>\n",
       "      <td>1.967149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>528</td>\n",
       "      <td>1.946600</td>\n",
       "      <td>1.933220</td>\n",
       "      <td>1.967241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>576</td>\n",
       "      <td>1.935700</td>\n",
       "      <td>1.936323</td>\n",
       "      <td>1.968111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>624</td>\n",
       "      <td>1.925800</td>\n",
       "      <td>1.934439</td>\n",
       "      <td>1.965540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>672</td>\n",
       "      <td>1.932800</td>\n",
       "      <td>1.937326</td>\n",
       "      <td>1.969467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>1.930400</td>\n",
       "      <td>1.936034</td>\n",
       "      <td>1.968576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>768</td>\n",
       "      <td>1.945600</td>\n",
       "      <td>1.934155</td>\n",
       "      <td>1.966611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>816</td>\n",
       "      <td>1.946000</td>\n",
       "      <td>1.938789</td>\n",
       "      <td>1.972232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>864</td>\n",
       "      <td>1.940200</td>\n",
       "      <td>1.933026</td>\n",
       "      <td>1.965484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>912</td>\n",
       "      <td>1.933400</td>\n",
       "      <td>1.934334</td>\n",
       "      <td>1.966546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>1.935600</td>\n",
       "      <td>1.936589</td>\n",
       "      <td>1.968670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1008</td>\n",
       "      <td>1.941800</td>\n",
       "      <td>1.936903</td>\n",
       "      <td>1.968971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1056</td>\n",
       "      <td>1.957000</td>\n",
       "      <td>1.930683</td>\n",
       "      <td>1.964914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1104</td>\n",
       "      <td>1.941400</td>\n",
       "      <td>1.931544</td>\n",
       "      <td>1.963266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1152</td>\n",
       "      <td>1.943900</td>\n",
       "      <td>1.930865</td>\n",
       "      <td>1.963295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.929900</td>\n",
       "      <td>1.937587</td>\n",
       "      <td>1.969115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1248</td>\n",
       "      <td>1.940600</td>\n",
       "      <td>1.931710</td>\n",
       "      <td>1.963688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1296</td>\n",
       "      <td>1.951500</td>\n",
       "      <td>1.936372</td>\n",
       "      <td>1.969447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1344</td>\n",
       "      <td>1.928700</td>\n",
       "      <td>1.934407</td>\n",
       "      <td>1.966930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1392</td>\n",
       "      <td>1.932400</td>\n",
       "      <td>1.937085</td>\n",
       "      <td>1.968339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>1.936700</td>\n",
       "      <td>1.926828</td>\n",
       "      <td>1.958579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1488</td>\n",
       "      <td>1.936200</td>\n",
       "      <td>1.942628</td>\n",
       "      <td>1.972401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1536</td>\n",
       "      <td>1.935400</td>\n",
       "      <td>1.932100</td>\n",
       "      <td>1.962641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1584</td>\n",
       "      <td>1.947400</td>\n",
       "      <td>1.936315</td>\n",
       "      <td>1.969082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1632</td>\n",
       "      <td>1.935400</td>\n",
       "      <td>1.937067</td>\n",
       "      <td>1.969324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>1.940300</td>\n",
       "      <td>1.927663</td>\n",
       "      <td>1.959038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1728</td>\n",
       "      <td>1.935600</td>\n",
       "      <td>1.929114</td>\n",
       "      <td>1.961572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1776</td>\n",
       "      <td>1.948600</td>\n",
       "      <td>1.928947</td>\n",
       "      <td>1.959684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1824</td>\n",
       "      <td>1.936400</td>\n",
       "      <td>1.932805</td>\n",
       "      <td>1.965195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1872</td>\n",
       "      <td>1.935200</td>\n",
       "      <td>1.927448</td>\n",
       "      <td>1.960399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>1.937700</td>\n",
       "      <td>1.936048</td>\n",
       "      <td>1.967503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1968</td>\n",
       "      <td>1.937700</td>\n",
       "      <td>1.932262</td>\n",
       "      <td>1.964505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2016</td>\n",
       "      <td>1.937100</td>\n",
       "      <td>1.928032</td>\n",
       "      <td>1.961636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2064</td>\n",
       "      <td>1.930200</td>\n",
       "      <td>1.931680</td>\n",
       "      <td>1.963616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2112</td>\n",
       "      <td>1.921700</td>\n",
       "      <td>1.934835</td>\n",
       "      <td>1.966079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2160</td>\n",
       "      <td>1.932800</td>\n",
       "      <td>1.941903</td>\n",
       "      <td>1.973378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2208</td>\n",
       "      <td>1.941500</td>\n",
       "      <td>1.933506</td>\n",
       "      <td>1.965537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2256</td>\n",
       "      <td>1.928600</td>\n",
       "      <td>1.937010</td>\n",
       "      <td>1.968068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2304</td>\n",
       "      <td>1.948300</td>\n",
       "      <td>1.935542</td>\n",
       "      <td>1.966967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2352</td>\n",
       "      <td>1.932900</td>\n",
       "      <td>1.936623</td>\n",
       "      <td>1.968574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>1.924600</td>\n",
       "      <td>1.934096</td>\n",
       "      <td>1.965677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2448</td>\n",
       "      <td>1.926400</td>\n",
       "      <td>1.938148</td>\n",
       "      <td>1.971717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2496</td>\n",
       "      <td>1.931500</td>\n",
       "      <td>1.931823</td>\n",
       "      <td>1.964031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2544</td>\n",
       "      <td>1.935600</td>\n",
       "      <td>1.932589</td>\n",
       "      <td>1.966032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2592</td>\n",
       "      <td>1.944100</td>\n",
       "      <td>1.936676</td>\n",
       "      <td>1.967277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2640</td>\n",
       "      <td>1.933100</td>\n",
       "      <td>1.936258</td>\n",
       "      <td>1.968914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2688</td>\n",
       "      <td>1.930900</td>\n",
       "      <td>1.939227</td>\n",
       "      <td>1.971020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2736</td>\n",
       "      <td>1.938800</td>\n",
       "      <td>1.932391</td>\n",
       "      <td>1.966381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2784</td>\n",
       "      <td>1.947300</td>\n",
       "      <td>1.936515</td>\n",
       "      <td>1.968419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2832</td>\n",
       "      <td>1.936000</td>\n",
       "      <td>1.937350</td>\n",
       "      <td>1.967931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2880</td>\n",
       "      <td>1.946100</td>\n",
       "      <td>1.938768</td>\n",
       "      <td>1.970242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2880, training_loss=1.9375227669874826, metrics={'train_runtime': 47260.378, 'train_samples_per_second': 1.948, 'train_steps_per_second': 0.061, 'total_flos': 0.0, 'train_loss': 1.9375227669874826, 'epoch': 30.0})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, './FirstMultiModel/EEGART')\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from SLT_dataloader import SignalDataCollator\n",
    "\n",
    "from tf_config import SLTConfig\n",
    "from tf_model import SLTModel\n",
    "from datetime import datetime\n",
    "\n",
    "# 获取当前日期时间，并格式化为 YYYYMMDD\n",
    "current_date = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# 替换路径中的日期\n",
    "output_dir = f\"./results/{current_date}_model_init_LR_05\"\n",
    "\n",
    "# 假設你的設備是 GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# slt_config = SLTConfig(src_channel_size=30, tgt_channel_size=3*5003, N=2, d_model = 1024)\n",
    "# slt_config.save_pretrained(\"test_slt_confit\")\n",
    "\n",
    "# slt_model = SLTModel(slt_config)\n",
    "# slt_model = slt_model.to(device)\n",
    "\n",
    "    \n",
    "def compute_metrics(eval_preds, batch_size=64):\n",
    "    predictions, targets = eval_preds\n",
    "    \n",
    "    loss_fct = nn.MSELoss()\n",
    "    num_samples = predictions.shape[0]\n",
    "    mse_sum = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    for start_idx in range(0, num_samples, batch_size):\n",
    "        end_idx = min(start_idx + batch_size, num_samples)\n",
    "        logits_batch = predictions[start_idx:end_idx]\n",
    "        labels_batch = targets[start_idx:end_idx]\n",
    "        logits = torch.tensor(logits_batch, dtype=torch.float32)\n",
    "        labels = torch.tensor(labels_batch, dtype=torch.float32)\n",
    "        # Compute the z-scores for the batch\n",
    "        logits_mean = torch.mean(logits, dim=0, keepdim=True)\n",
    "        logits_std = torch.std(logits, dim=0, keepdim=True)\n",
    "        logits_norm = (logits - logits_mean) / (logits_std + 1e-10)\n",
    "        \n",
    "        labels_mean = torch.mean(labels, dim=0, keepdim=True)\n",
    "        labels_std = torch.std(labels,  dim=0, keepdim=True)\n",
    "        labels_norm = (labels - labels_mean) / (labels_std + 1e-10)\n",
    "\n",
    "        if torch.isnan(logits_norm).any() or torch.isinf(logits_norm).any():\n",
    "            print(\"logits_norm contains nan or inf\")\n",
    "        if torch.isnan(labels_norm).any() or torch.isinf(labels_norm).any():\n",
    "            print(\"labels_norm contains nan or inf\")\n",
    "        \n",
    "        # Compute batch MSE\n",
    "        mse_sum += loss_fct(logits_norm, labels_norm).item()\n",
    "        num_batches += 1\n",
    "\n",
    "    # Return the average MSE\n",
    "    avg_mse = mse_sum / num_batches\n",
    "    \n",
    "    del logits, labels, logits_norm, labels_norm\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return {\"mse\": avg_mse}\n",
    "\n",
    "# 包裝自定義的初始化方法\n",
    "def huggingface_model_init():\n",
    "    slt_config = SLTConfig(src_channel_size=30, tgt_channel_size=3*5003, N=2, d_model = 1024)\n",
    "    slt_config.save_pretrained(\"test_slt_confit\")\n",
    "    slt_model = SLTModel(slt_config)\n",
    "    slt_model = slt_model.to(device)\n",
    "    for p in slt_model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            torch.nn.init.xavier_uniform_(p)\n",
    "    return slt_model\n",
    "\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=48,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    eval_accumulation_steps=5,\n",
    "    num_train_epochs=30,\n",
    "    weight_decay=0.01,\n",
    "    learning_rate = 0.01,\n",
    "    lr_scheduler_type = \"constant\",\n",
    "    # fp16=True,\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    report_to=\"wandb\",\n",
    ")\n",
    "\n",
    "# 初始化模型和 Trainer\n",
    "trainer = Trainer(\n",
    "    # model=slt_model,\n",
    "    model_init=huggingface_model_init,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    data_collator=SignalDataCollator(),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# 开始训练\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
